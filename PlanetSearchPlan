# Data Acquition
1. Obtain ligth curve data from TESS archives
2. LightCurve has functions that allow search for and download this data directly within the package

# Preprocessing Data
1. clean the light curva data using lightKurve's tools
2. remove noise,outliers, normalize the data, correct systematic trends

# Transit Search
1. algo to search for periodic dips in brightness

# Transit modeling
1. once transits are found,  model them to estimate the planet's properties like size, orbital period

# Valildation
1. confirm that signals are from planets and not false positvies
2. check consistent transit depth, duration and shape 

####### Automation ######## 
1. Data retrivel ---> use MAST API to retrieve light curve data
2. Automate ---> the download and storage of light currve files using a scheduled job and a trigger based on data availability
3. Preprocessing ---> write scripts using LightKurve or similar library to clean the data ---. flatten the curve,remove outliers, noramlize the flux --> Automate all this
4. Transit signal detection --> Apply algorithms like BLS to search for periodic dips in brightness. ---> implement additional filtters to exclude false positives
5. candidate validation ---> use machine learning models trained on confirmed exoplanets to predict the likliehood of each candidate ---> features could include transit parameters, stellar characteristics and derived statistical measures --> implement feedback loo where candidates marked as false positives help retrain the model 
6. Catalogue and review ---> store detected candidates in db with all parameters ---> provide web interface for astronomers to review candidates
7. Notification system ---> create alerts for high probability candidates 
8. Integration with Observatories ---> for high probability candidates, automate the process of requesting follow up observations from ground based observatories. 

#### RESOURCES ######
# database
# web interface
# security


############################################################################################################################################\
############## SET UP JAVA BACKEND ####################3
# create java classes to represent Light curve data model---->  LightCurve.java
--> @Entity enables this class to map with corresponding table in DB
--> integration point for TESS API
--> others depend on the data stored in instances of this class

# LightCurveRepository.java
---> provides CRUD
---> methods to findall, searchall, etc.

# LightCurveService.java
---> business logic
---> interact with LightCurveRepository for database operations

# LightCurveController.java
---> handles http requests and interacts with Service.java to perform operations 
---> endpoint for retrieving curves by ID, adding new curve

####### API CALL TO TESS #############  PYTHON     ######################################################################################
# Setup python environment ---> will both handle API and preprocessing and java an setup an API later with python module if needed data 
# Setup python virtual environment ---> python3 -m venv venv in project directory  --->  terminal changes to venv in front of kali user
# pip instal requests for http and pip install pandas for data handling

# ####### understand TESS API ########
# it's endpoints, request format, structure of the response data
---> root URL
---> specific URLs for different data sets
---> Request methods
---> query parameters
----> response format
---> reate limits 
-->  authentication
-------------> TEST --> curl,postman or python requests 
# options options options options options options options options options options options options options options options 

# csv files bullk download ---> https://archive.stsci.edu/tess/bulk_downloads/bulk_downloads_tce.html

# Mast astroquery.mast ----> https://astroquery.readthedocs.io/en/latest/mast/mast.html
 ---> pip install astroquery
 ----> 


# Identify specific data sets ---> e.g ---> light curve, full-frame images etc. 
---> query parameters ---> target names, coordinates, mission, instruments
---> frame plot ---> how to decide which ??? ---> code to examine muliple frames to identify best aperture, check consistency across different frames. 



# data retrievel scripts to automate the querying




# write python functions/classes for preprocessing steps
--> data cleaning ---> remove artifacts or errorneous readings
--> Data transformation ---> format

# Algorithm for analysis

# Data storage to sql

# Python-java integration with Flask or FastAPI 

